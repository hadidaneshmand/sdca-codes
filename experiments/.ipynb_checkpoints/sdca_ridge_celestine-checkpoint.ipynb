{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def readfile(filename, n,d):\n",
    "    y = np.zeros(n) # targets\n",
    "    X = np.zeros((n,d)) # input matrix each row is a sample data point\n",
    "    li = 0 \n",
    "    with open(filename, \"rb\") as f:\n",
    "        for line in f:\n",
    "           if li>=n : \n",
    "             break;\n",
    "           parts = line.split()\n",
    "           y[li] = float(parts[0])\n",
    "           for i in range(len(parts)): \n",
    "                if i >0 and parts[i] != '\\n': \n",
    "                    fparts = parts[i].split(\":\")\n",
    "                    X[li,int(fparts[0])-1] = float(fparts[1])\n",
    "           li = li +1\n",
    "    return (y,X)\n",
    "def get_data_plot(stats):\n",
    "    xvals = np.array([x1 for x1, y1 in stats])\n",
    "    yvals = np.array([y1 for x1, y1 in stats])\n",
    "    return (xvals,yvals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w_alpha(alpha,X,lambd): # check the equation 3 of (SDCA) paper\n",
    "    n, d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    for i in range(n): \n",
    "        w = w + alpha[i]*X[i,:]/(lambd)\n",
    "    return w\n",
    "\n",
    "def dual_obj(w, alpha,X,y,lambd): # computes the dual function value for a given parameter alpha \n",
    "    da = 0\n",
    "    n, d = X.shape\n",
    "    for i in range(n):         \n",
    "        da = da + alpha[i]*y[i] - 0.5*n*alpha[i]*alpha[i]\n",
    "    da = da\n",
    "    da = da - 0.5*pow(np.linalg.norm(np.dot(alpha,X)),2)/lambd\n",
    "    return da\n",
    "def dual_printer(w, alpha,X,y,lambd): # computes the dual function value for a given parameter alpha \n",
    "    da = 0\n",
    "    n, d = X.shape\n",
    "    for i in range(n):         \n",
    "        da = da - 0.5*n*alpha[i]*alpha[i]\n",
    "    print('first term = {}'.format(da))\n",
    "    da2 = 0\n",
    "    for i in range(n): \n",
    "        da2 = da2 + alpha[i]*y[i] \n",
    "    print('second term = {}'.format(da2))\n",
    "    da3 = -0.5*pow(np.linalg.norm(np.dot(alpha,X)),2)/lambd\n",
    "    print('third term = {}'.format(da3))\n",
    "    da = da + da2 + da3\n",
    "    return da\n",
    "def primal_func(w,alpha,X,y,lambd): # computes the primal value for the given parameter w\n",
    "    n, d = X.shape\n",
    "    pw = 0\n",
    "    for i in range(n): \n",
    "        dif = np.dot(X[i,:],w) - y[i]\n",
    "        pw = pw + dif*dif\n",
    "    pw = pw/(2*float(n))\n",
    "    pw = pw + 0.5*lambd*pow(np.linalg.norm(w),2)\n",
    "    return pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dual_rigde(X,y, lambd, num_effective_passes,obj = dual_obj, verbose = False):\n",
    "  # each row contains a data point with dim d\n",
    "  # active_stargey: case -1 (nothing), case 1 (reset the block list in each iteration), case 2 ( holding a queue with a limited size), case 3 (online random permutation replacement) \n",
    "  sq_row_norms =  np.square(np.linalg.norm(X, axis=1))\n",
    "  n, d = X.shape\n",
    "  rperm = np.random.permutation(n);\n",
    "  alpha = np.zeros(n)\n",
    "  w = w_alpha(alpha,X,lambd)\n",
    "  obj_value = obj(w,alpha,X,y,lambd) \n",
    "  sample_size = n\n",
    "  if verbose:\n",
    "    print(\" Initial objective value: {}\".format(obj_value))\n",
    "  past_ef_pass = 0\n",
    " \n",
    "  stats = [(0.0, obj_value)]\n",
    "  completed_effective_passes = 0.0\n",
    "  while completed_effective_passes < num_effective_passes:\n",
    "    #if(completed_effective_passes>20.0):\n",
    "    #    sample_size_old = sample_size # Celestine's pointer\n",
    "    #    sample_size = n\n",
    "    #    w = (sample_size_old/sample_size)*w\n",
    "#     if(completed_effective_passes>30.0): \n",
    "#        lambd = 1.0/n     \n",
    "    coords = rperm[np.random.permutation(sample_size)] \n",
    "    for ii in coords:\n",
    "        alpha_i_old = alpha[ii]\n",
    "        xi = X[ii,:]\n",
    "        sqi = sq_row_norms[ii]\n",
    "        yi = y[ii]\n",
    "        # coordinate update step \n",
    "        delta_alpha_i = (yi- np.dot(xi,w)-sample_size*alpha_i_old)/(sample_size+(sqi/lambd)) \n",
    "        alpha[ii] = alpha[ii] + delta_alpha_i\n",
    "        w = w + delta_alpha_i*xi/(lambd)\n",
    "    past_ef_pass = completed_effective_passes\n",
    "    completed_effective_passes += len(coords) / float(n)\n",
    "    obj_value = obj(w,alpha,X,y,lambd)\n",
    "    stats.append((completed_effective_passes, obj_value))\n",
    "    if verbose:\n",
    "      print(\"Obj[{}]= {},delta_alpha = {},sqi={}\".format(completed_effective_passes, obj_value,(np.dot(xi,w)),sqi))\n",
    "  return (alpha, stats,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_dual_rigde(X,y, lambd, num_effective_passes,main_samplesize,obj = dual_obj, verbose = False):\n",
    "  # each row contains a data point with dim d\n",
    "  # active_stargey: case -1 (nothing), case 1 (reset the block list in each iteration), case 2 ( holding a queue with a limited size), case 3 (online random permutation replacement) \n",
    "  sq_row_norms =  np.square(np.linalg.norm(X, axis=1))\n",
    "  n, d = X.shape\n",
    "  rperm = np.random.permutation(n);\n",
    "  alpha = np.zeros(n)\n",
    "  w = w_alpha(alpha,X,lambd)\n",
    "  obj_value = obj(w,alpha,X,y,lambd) \n",
    "  sample_size = n\n",
    "  if verbose:\n",
    "    print(\" Initial objective value: {}\".format(obj_value))\n",
    "  past_ef_pass = 0\n",
    " \n",
    "  stats = [(0.0, obj_value)]\n",
    "  completed_effective_passes = 0.0\n",
    "  while completed_effective_passes < num_effective_passes:\n",
    "    #if(completed_effective_passes>20.0):\n",
    "    #    sample_size_old = sample_size # Celestine's pointer\n",
    "    #    sample_size = n\n",
    "    #    w = (sample_size_old/sample_size)*w\n",
    "#     if(completed_effective_passes>30.0): \n",
    "#        lambd = 1.0/n     \n",
    "    coords = rperm[np.random.permutation(sample_size)] \n",
    "    for ii in coords:\n",
    "        alpha_i_old = alpha[ii]\n",
    "        xi = X[ii,:]\n",
    "        sqi = sq_row_norms[ii]\n",
    "        yi = y[ii]\n",
    "        # coordinate update step \n",
    "        delta_alpha_i = (yi- np.dot(xi,w)-main_samplesize*alpha_i_old)/(main_samplesize+(sqi/lambd)) \n",
    "        alpha[ii] = alpha[ii] + delta_alpha_i\n",
    "        w = w + delta_alpha_i*xi/(lambd)\n",
    "    past_ef_pass = completed_effective_passes\n",
    "    completed_effective_passes += len(coords) / float(n)\n",
    "    obj_value = obj(w,alpha,X,y,lambd)\n",
    "    stats.append((completed_effective_passes, obj_value))\n",
    "    if verbose:\n",
    "      print(\"Obj[{}]= {},delta_alpha = {},sqi={}\".format(completed_effective_passes, obj_value,(np.dot(xi,w)),sqi))\n",
    "  return (alpha, stats,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dual_adaptreg_rigde(X,y, lambd_main, num_effective_passes,init_lambda,obj = dual_obj, verbose = False):\n",
    "  # each row contains a data point with dim d\n",
    "  # active_stargey: case -1 (nothing), case 1 (reset the block list in each iteration), case 2 ( holding a queue with a limited size), case 3 (online random permutation replacement) \n",
    "  sq_row_norms =  np.square(np.linalg.norm(X, axis=1))\n",
    "  n, d = X.shape\n",
    "  rperm = np.random.permutation(n);\n",
    "  alpha = np.zeros(n)\n",
    "  lambd = init_lambda\n",
    "  w = w_alpha(alpha,X,lambd)\n",
    "  obj_value = obj(w,alpha,X,y,lambd_main) \n",
    "  sample_size = n\n",
    "  if verbose:\n",
    "    print(\" Initial objective value: {}\".format(obj_value))\n",
    "  past_ef_pass = 0\n",
    "  stats = [(0.0, obj_value)]\n",
    "  completed_effective_passes = 0.0\n",
    "  while completed_effective_passes < num_effective_passes:\n",
    "#     if(completed_effective_passes==10.0):\n",
    "#         print('befor={}'.format(obj(w,alpha,X,y,lambd_main)))\n",
    "#         w = w*5.0\n",
    "#         lambd = lambd/5.0\n",
    "#         print('after={}'.format(obj(w,alpha,X,y,lambd_main)))\n",
    "    if(completed_effective_passes==15.0):\n",
    "#         print('befor={}'.format(obj(w,alpha,X,y,lambd_main)))\n",
    "        w = (lambd/lambd_main)*w\n",
    "        lambd = lambd_main\n",
    "#         print('after={}'.format(obj(w,alpha,X,y,lambd_main)))\n",
    "#     if(lambd>lambd_main and (completed_effective_passes % 3 == 0)): \n",
    "#         new_lambd = max(lambd/2.0,lambd_main)\n",
    "#         w = (lambd/new_lambd)*w\n",
    "#         lambd = new_lambd\n",
    "    coords = rperm[np.random.permutation(sample_size)] \n",
    "    for ii in coords:\n",
    "        alpha_i_old = alpha[ii]\n",
    "        xi = X[ii,:]\n",
    "        sqi = sq_row_norms[ii]\n",
    "        yi = y[ii]\n",
    "        # coordinate update step \n",
    "        delta_alpha_i = (yi- np.dot(xi,w)-0.5*alpha_i_old)/(0.5+sqi/(lambd*sample_size)) \n",
    "        alpha[ii] = alpha[ii] + delta_alpha_i\n",
    "        w = w + delta_alpha_i*xi/(lambd*sample_size)\n",
    "    past_ef_pass = completed_effective_passes\n",
    "    completed_effective_passes += len(coords) / float(n)\n",
    "    obj_value = obj(w,alpha,X,y,lambd_main)\n",
    "    stats.append((completed_effective_passes, obj_value))\n",
    "    if verbose:\n",
    "      print(\"Obj[{}]= {},delta_alpha = {},sqi={}\".format(completed_effective_passes, obj_value,(np.dot(xi,w)),sqi))\n",
    "  return (alpha, stats,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_small_experiment(X,y,lambd,passes,plotname,primal_accuracy = False):\n",
    "    num = 4\n",
    "    rep = 4\n",
    "    N,d = X.shape\n",
    "    main_opt = 0\n",
    "    clf = Ridge(alpha=lambd*N,fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    primal_opt =  primal_func(clf.coef_,0,X,y,lambd)\n",
    "    print(\"primal obj={}\".format(primal_opt))\n",
    "    def dist_opt(w,alpha,X2,y2,lambd2):\n",
    "      if primal_accuracy == True: \n",
    "        return primal_func(w,alpha,X2,y2,lambd) - primal_opt\n",
    "      return primal_opt - dual_obj(w, alpha,X2,y2,lambd)\n",
    "            #da = 0\n",
    "            #for i in range(n): \n",
    "            #    if alpha[i] <= 1 and alpha[i] >= 0:\n",
    "            #        da = da + alpha[i]\n",
    "            #    else:\n",
    "            #        da = da + float(\"inf\")\n",
    "            #da = da / n \n",
    "            #da = da - 0.5*lambd*np.square(((1.0*n)/N)*np.linalg.norm(w_alpha(alpha,A,lambd)))\n",
    "            #return primal_opt - da\n",
    "    (alpha_n,stats_n,w_n) = dual_rigde( X, y, lambd, passes, obj = dist_opt,verbose=True)\n",
    "    t_randomperm, f_randomperm = get_data_plot(stats_n)  \n",
    "    converge_rate = f_randomperm\n",
    "    plabel = \"lambda = 1/n\"\n",
    "    plt.plot(t_randomperm,np.log10(f_randomperm),label = plabel, marker='o')\n",
    "#     (alpha_f,stats_f,w_f) =dual_adaptreg_rigde( X,y, lambd, passes, obj = dist_opt,init_lambda = 10*lambd)\n",
    "#     t_randomperm, f_randomperm = get_data_plot(stats_f)  \n",
    "#     converge_rate = f_randomperm\n",
    "#     plabel = \"lambda = 10/n\"\n",
    "#     plt.plot(t_randomperm,np.log10(f_randomperm),label = plabel, marker='o')\n",
    "#     lgd = plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5)\n",
    "#     plt.savefig(plotname, facecolor='w', edgecolor='w', orientation='portrait',  format='eps', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    return alpha_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def distributed_test(X_in,y_in,lambd,k):\n",
    "    n, d = X_in.shape\n",
    "    rperm = np.random.permutation(n)\n",
    "    X = X_in[rperm,:]\n",
    "    y = y_in[rperm]\n",
    "    clf = Ridge(alpha=lambd*n,fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    primal_opt =  primal_func(clf.coef_,0,X,y,lambd)\n",
    "    kf = KFold(n_splits=k)\n",
    "    alpha_agg = np.zeros(n)\n",
    "    T = 0\n",
    "    w = np.zeros(d)\n",
    "    for train, test in kf.split(X):\n",
    "        T = T + 1\n",
    "        sub_X = X[test,:]\n",
    "        sub_y = y[test] \n",
    "        m = len(test)\n",
    "        sub_lambd = lambd*k\n",
    "        clf = Ridge(alpha=sub_lambd*m,fit_intercept=False)\n",
    "        clf.fit(sub_X, sub_y)\n",
    "        primal_sub_opt =  primal_func(clf.coef_,0,sub_X,sub_y,sub_lambd)\n",
    "        (sub_alpha,_,sub_w) = dual_rigde( sub_X, sub_y, sub_lambd, num_effective_passes = 320, obj = primal_func)\n",
    "#         w = np.add(w,sub_w)\n",
    "        subopt = primal_sub_opt - primal_func(sub_w,0,sub_X,sub_y,sub_lambd)\n",
    "        alpha_agg[test] = sub_alpha/float(k)\n",
    "        print('optimalit[{}] = {}'.format(T,subopt))\n",
    "        print(alpha_agg[test[1:10]])\n",
    "#     w = w/float(k)\n",
    "    for i in range(n): \n",
    "        w = np.add(w,alpha_agg[i]*X[i,:])\n",
    "    w = w/(lambd*k)\n",
    "    final_subopt = primal_opt - dual_obj(0,alpha_agg,X,y,lambd)\n",
    "    primal_subopt = primal_func(w,0,X,y,lambd)-primal_opt \n",
    "    print('final dual optimality = {}, primal = {}'.format(final_subopt,primal_subopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def partial_distributed_test(X_in,y_in,lambd,k):\n",
    "    n, d = X_in.shape\n",
    "    rperm = np.random.permutation(n)\n",
    "    X = X_in[rperm,:]\n",
    "    y = y_in[rperm]\n",
    "    clf = Ridge(alpha=lambd*n,fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    primal_opt =  primal_func(clf.coef_,0,X,y,lambd)\n",
    "    kf = KFold(n_splits=k)\n",
    "    alpha_agg = np.zeros(n)\n",
    "    T = 0 \n",
    "    for train, test in kf.split(X):\n",
    "        T = T + 1\n",
    "        sub_X = X[test,:]\n",
    "        sub_y = y[test] \n",
    "        m = len(test)\n",
    "        sub_lambd = lambd\n",
    "        (sub_alpha,_,_) = partial_dual_rigde( sub_X, sub_y, sub_lambd, num_effective_passes = 260, obj = primal_func,main_samplesize = n)\n",
    "        alpha_agg[test] = sub_alpha\n",
    "    w = w_a\n",
    "    final_subopt = primal_opt - dual_obj(0,alpha_agg,X,y,lambd)\n",
    "    \n",
    "    print('final suboptimality = {}'.format(final_subopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def clustered_distributed_test(X_in,y_in,lambd,k):\n",
    "    n, d = X_in.shape\n",
    "    classes = KMeans(n_clusters=k).fit_predict(X)\n",
    "    clf = Ridge(alpha=lambd*n,fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    primal_opt =  primal_func(clf.coef_,0,X,y,lambd)\n",
    "    alpha_agg = np.zeros(n)\n",
    "    for i in range(k):\n",
    "        print(i)\n",
    "        inds = classes == i\n",
    "        sub_X = X[inds,:]\n",
    "        sub_y = y[inds] \n",
    "        m = sum(inds)\n",
    "        print(m)\n",
    "        sub_lambd = lambd\n",
    "        (sub_alpha,_,_) = partial_dual_rigde( sub_X, sub_y, sub_lambd, num_effective_passes = 210, obj = primal_func,main_samplesize = n)\n",
    "        alpha_agg[inds] = sub_alpha\n",
    "    final_subopt = primal_opt - dual_obj(0,alpha_agg,X,y,lambd)\n",
    "    print('final suboptimality = {}'.format(final_subopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def dual_transfer_test(X,y,lambd,k):\n",
    "    n, d = X.shape\n",
    "    clf = Ridge(alpha=lambd*n,fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    primal_opt =  primal_func(clf.coef_,0,X,y,lambd)\n",
    "    hn = int(n/2.0)\n",
    "    rperm = np.random.permutation(n)\n",
    "    alpha_full = np.zeros(n) \n",
    "    inds = rperm[0:hn]\n",
    "    sub_X = X[inds,:]\n",
    "    sub_y = y[inds] \n",
    "    sub_lambd = lambd\n",
    "    clf = Ridge(alpha=sub_lambd,fit_intercept=False)\n",
    "    clf.fit(sub_X, sub_y)\n",
    "    primal_sub_opt =  primal_func(clf.coef_,0,sub_X,sub_y,sub_lambd)\n",
    "    (sub_alpha,_,sub_w) = dual_rigde( sub_X, sub_y, sub_lambd, num_effective_passes = 280, obj = primal_func)\n",
    "    subopt = primal_sub_opt - primal_func(sub_w,0,sub_X,sub_y,sub_lambd)\n",
    "    alpha_full[inds] = sub_alpha/2.0\n",
    "    for ii in rperm[hn:n]:\n",
    "        best_index = 1 \n",
    "        best_dot = -1000\n",
    "        for jj in rperm[0:hn]: \n",
    "            dot = np.dot(X[jj,:],np.transpose(X[ii,:])) \n",
    "            if dot > best_dot : \n",
    "                best_index = jj\n",
    "                best_dot = dot\n",
    "        alpha_full[ii] = alpha_full[best_index]/2.0\n",
    "    final_subopt = primal_opt - dual_obj(0,alpha_full,X,y,lambd)\n",
    "    print('final dual optimality = {}'.format(final_subopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimalit[1] = -0.0136435863565\n",
      "[ -9.83061949e-05   3.38671192e-07   3.08201283e-04  -6.86767548e-05\n",
      "  -5.63138785e-05  -1.94882368e-04   1.77522737e-04  -2.23124725e-07\n",
      "   3.02233800e-04]\n",
      "optimalit[2] = -0.00152253811153\n",
      "[  3.88403681e-05  -3.47650938e-05  -9.79323702e-05  -2.54975254e-04\n",
      "   3.73469633e-04  -6.87368369e-05  -2.45124912e-04   2.91494405e-04\n",
      "  -9.47293159e-05]\n",
      "final dual optimality = 0.0114541301166, primal = 0.00568418512442\n"
     ]
    }
   ],
   "source": [
    "n = 3250; \n",
    "d = 123; \n",
    "import readsvm \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#filename = \"../datasets/rcv1_train.binary\"\n",
    "filename = \"../datasets/a9a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "# X = preprocessing.normalize(X, norm='l2')\n",
    "lambd = 0.1/n\n",
    "passes = 160\n",
    "k = 2\n",
    "distributed_test(X,y,lambd,k)\n",
    "#clustered_distributed_test(X,y,lambd,k)\n",
    "#dual_transfer_test(X,y,lambd,k)\n",
    "#partial_distributed_test(X,y,lambd,k)\n",
    "#alpha = run_small_experiment(X,y, lambd,passes,\"plot/a9a_ridge_dual.eps\",primal_accuracy =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 0, 0, 0, 2, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primal obj=0.224240528007\n",
      " Initial objective value: 0.224240528007\n",
      "Obj[1.0]= 0.196052202605,delta_alpha = -1.03235726574,sqi=14.0\n",
      "Obj[2.0]= 0.17129233873,delta_alpha = 0.952948655693,sqi=14.0\n",
      "Obj[3.0]= 0.149749475479,delta_alpha = -1.01700729517,sqi=14.0\n",
      "Obj[4.0]= 0.130924760908,delta_alpha = -0.957917441586,sqi=14.0\n",
      "Obj[5.0]= 0.11432671938,delta_alpha = 0.801435512708,sqi=14.0\n",
      "Obj[6.0]= 0.0999779834008,delta_alpha = 0.648313852258,sqi=14.0\n",
      "Obj[7.0]= 0.087277428298,delta_alpha = 0.610825293919,sqi=14.0\n",
      "Obj[8.0]= 0.0762273062746,delta_alpha = -0.805655864335,sqi=14.0\n",
      "Obj[9.0]= 0.0665727041678,delta_alpha = -0.991300364663,sqi=14.0\n",
      "Obj[10.0]= 0.0581411229077,delta_alpha = -0.8659987044,sqi=14.0\n",
      "Obj[11.0]= 0.0507915163947,delta_alpha = -0.988311633307,sqi=14.0\n",
      "Obj[12.0]= 0.0444214969007,delta_alpha = 0.374384834147,sqi=14.0\n",
      "Obj[13.0]= 0.0389016186705,delta_alpha = -0.945247489305,sqi=14.0\n",
      "Obj[14.0]= 0.034008814596,delta_alpha = -0.754250163874,sqi=14.0\n",
      "Obj[15.0]= 0.0296995346432,delta_alpha = -1.04460941259,sqi=14.0\n",
      "Obj[16.0]= 0.0259690317124,delta_alpha = -0.94130659403,sqi=14.0\n",
      "Obj[17.0]= 0.0226988928012,delta_alpha = -0.379451584668,sqi=14.0\n",
      "Obj[18.0]= 0.0198516974129,delta_alpha = 0.683638207219,sqi=14.0\n",
      "Obj[19.0]= 0.0173196991829,delta_alpha = -0.96398053206,sqi=12.0\n",
      "Obj[20.0]= 0.0151380508725,delta_alpha = -0.604949688584,sqi=14.0\n",
      "Obj[21.0]= 0.013235029149,delta_alpha = -1.33394177989,sqi=14.0\n",
      "Obj[22.0]= 0.0115742097068,delta_alpha = 1.16520697732,sqi=14.0\n",
      "Obj[23.0]= 0.0101090062727,delta_alpha = -0.134504587132,sqi=14.0\n",
      "Obj[24.0]= 0.008836840426,delta_alpha = -0.358616907925,sqi=14.0\n",
      "Obj[25.0]= 0.00771776859127,delta_alpha = -1.13885577932,sqi=14.0\n",
      "Obj[26.0]= 0.00673958798256,delta_alpha = -0.0774981866407,sqi=14.0\n",
      "Obj[27.0]= 0.00589326009318,delta_alpha = -0.864155274559,sqi=14.0\n",
      "Obj[28.0]= 0.00515428978276,delta_alpha = -1.13133696017,sqi=14.0\n",
      "Obj[29.0]= 0.00450439175127,delta_alpha = -0.0425554307625,sqi=14.0\n",
      "Obj[30.0]= 0.00393519478428,delta_alpha = -0.824572680459,sqi=14.0\n",
      "Obj[31.0]= 0.00344002147617,delta_alpha = -0.805254081869,sqi=14.0\n",
      "Obj[32.0]= 0.00300933145165,delta_alpha = -1.14798082534,sqi=14.0\n",
      "Obj[33.0]= 0.00263253805303,delta_alpha = -1.07894937805,sqi=14.0\n",
      "Obj[34.0]= 0.00230274733205,delta_alpha = -0.292268722313,sqi=14.0\n",
      "Obj[35.0]= 0.00201402167641,delta_alpha = -1.0328871434,sqi=14.0\n",
      "Obj[36.0]= 0.00176059953344,delta_alpha = -0.672040896698,sqi=14.0\n",
      "Obj[37.0]= 0.00153950491005,delta_alpha = -0.966290294788,sqi=14.0\n",
      "Obj[38.0]= 0.00134617194762,delta_alpha = -0.347738183309,sqi=14.0\n",
      "Obj[39.0]= 0.00117682993836,delta_alpha = 0.856660950651,sqi=14.0\n",
      "Obj[40.0]= 0.00102830864842,delta_alpha = -0.901714837163,sqi=14.0\n",
      "Obj[41.0]= 0.000899202618492,delta_alpha = -1.00774317084,sqi=14.0\n",
      "Obj[42.0]= 0.000787040397385,delta_alpha = -0.470332398521,sqi=14.0\n",
      "Obj[43.0]= 0.00068852482644,delta_alpha = -0.373783185723,sqi=14.0\n",
      "Obj[44.0]= 0.000601723828649,delta_alpha = -1.09624589127,sqi=14.0\n",
      "Obj[45.0]= 0.000526146136411,delta_alpha = -0.505381735575,sqi=14.0\n",
      "Obj[46.0]= 0.000460057175912,delta_alpha = -0.340919020931,sqi=14.0\n",
      "Obj[47.0]= 0.000402384133787,delta_alpha = -0.617892961068,sqi=14.0\n",
      "Obj[48.0]= 0.000352033615282,delta_alpha = -0.461248156383,sqi=14.0\n",
      "Obj[49.0]= 0.000307647296428,delta_alpha = -0.29367797014,sqi=14.0\n",
      "Obj[50.0]= 0.000268968605063,delta_alpha = -1.0648770338,sqi=14.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvjNhCE/lFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e87450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 32561; \n",
    "d = 123; \n",
    "import readsvm \n",
    "\n",
    "filename = \"../datasets/a9a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "# X = preprocessing.normalize(X, norm='l2')\n",
    "lambd = 1.0/float(n)\n",
    "passes = 50\n",
    "alpha = run_small_experiment(X,y, lambd,passes,\"plot/a9a_dual_sdca.eps\",primal_accuracy =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 32561; \n",
    "d = 123; \n",
    "primal_accuracy = False\n",
    "epochs = int(20)\n",
    "import readsvm \n",
    "\n",
    "filename = \"../datasets/a9a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "for i in range(n):\n",
    "    if(y[i]==2 or y[i] == 0):\n",
    "        y[i] = -1;\n",
    "lambd = 1.0/float(n)\n",
    "clf = Ridge(alpha=lambd*n,fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "primal_opt =  primal_func(clf.coef_,0,X,y,lambd)\n",
    "print(\"primal obj={}\".format(primal_opt))\n",
    "def dist_opt(w,alpha,X2,y2,lambd2):\n",
    "  if primal_accuracy == True: \n",
    "    return primal_func(w,alpha,X2,y2,lambd) - primal_opt\n",
    "  return primal_opt - dual_obj(w, alpha,X2,y2,lambd)\n",
    "alpha,stat_sgd,w = sgd_for_sdca_rigde(X,y,lambd,epochs,obj = dist_opt, verbose = True)\n",
    "alpha,stat_sdca,w = dual_rigde(X,y, lambd, epochs,n,obj = dist_opt, verbose = False)\n",
    "t_sgd,err_sgd = get_data_plot(stat_sgd)\n",
    "t_sdca,err_sdca = get_data_plot(stat_sdca)\n",
    "plt.plot(t_sgd,np.log10(err_sgd),label='sgd')\n",
    "plt.plot(t_sdca,np.log10(err_sdca),label='sdca')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primal obj=0.177731070802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -1.01014633e-05,  -1.86567276e-05,  -2.01009066e-05, ...,\n",
       "        -1.20243525e-05,   5.60481238e-06,  -2.18455798e-06])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAEeBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109b3fc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 49749; \n",
    "d = 300; \n",
    "filename = \"../datasets/w8a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "A = np.zeros((n,d))\n",
    "for i in range(n):\n",
    "    if(y[i]==2 or y[i] == 0):\n",
    "        y[i] = -1;\n",
    "    A[i,:] = y[i]*X[i,:]\n",
    "lambd = 1.0/n\n",
    "passes = 40\n",
    "run_small_experiment(X,y,lambd,passes,\"plot/w8a_ridge_primal.eps\",primal_accuracy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 49749; \n",
    "d = 300; \n",
    "filename = \"../datasets/w8a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "# X = preprocessing.normalize(X, norm='l2')\n",
    "for i in range(n):\n",
    "    if(y[i]==2 or y[i] == 0):\n",
    "        y[i] = -1;\n",
    "lambd = 1.0/n\n",
    "passes = 40\n",
    "run_small_experiment(X,y,lambd,passes,\"plot/w8a_dual_sdca.eps\",primal_accuracy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 50100; \n",
    "d = 54; \n",
    "filename = \"../datasets/covtype.libsvm.binary.scale\"\n",
    "y, X = readfile(filename,n,d)\n",
    "for i in range(n):\n",
    "    if(y[i]==2 or y[i] == 0):\n",
    "        y[i] = -1;\n",
    "lambd = 1.0/n\n",
    "passes = 40\n",
    "run_small_experiment(X,y,lambd,passes,\"plot/covtype_dual_sdca.eps\",primal_accuracy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distance_plot(X,y,n,d,lambd,nr,pivotsi,verbose = True):\n",
    "    print(max(np.linalg.norm(X,axis =1 )))\n",
    "    if(verbose):\n",
    "        print(\"Loading Data Accomblished\")\n",
    "    indices = np.random.choice(n, pivotsi, replace=False)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    t1,t2 = X.shape\n",
    "    print('t1:{},t2:{}'.format(t1,t2))\n",
    "    for i in range(len(y)): \n",
    "        if y[i] == 2 :\n",
    "            y[i] = -1\n",
    "    n = pivotsi\n",
    "    x0 = np.zeros(d)\n",
    "    csize = 256\n",
    "    sizes = [csize]\n",
    "    while csize < (n/4.0):\n",
    "        csize = 2* csize\n",
    "        sizes.append(csize)\n",
    " \n",
    "    clf = Ridge(alpha=lambd*n,fit_intercept=False) \n",
    "    pivot = clf.fit(X, y).coef_\n",
    "    pivot_primal = primal_func(pivot,0,X,y,lambd)\n",
    "    print(\"precision:{},pivot_norm:{}\".format(primal_func(pivot,0,X,y,lambd),(np.linalg.norm(pivot))))\n",
    "    spivot = str(pivot)[2:-2]\n",
    "    \n",
    "    dists= np.zeros((len(sizes),nr))\n",
    "    angles = np.zeros((len(sizes),nr))\n",
    "    for i in range(len(sizes)):\n",
    "        subsamplsi = sizes[i]\n",
    "        for j in range(nr):\n",
    "#             print('subsample size:{}'.format(subsamplsi))\n",
    "            subindices = np.random.choice(n, subsamplsi, replace=False)\n",
    "            lambd_s = 1.0/subsamplsi\n",
    "            clf2 = Ridge(alpha=lambd_s*n,fit_intercept=False)\n",
    "            clf2.fit(X, y)\n",
    "            ws = clf2.coef_\n",
    "            dist = primal_func(ws,0,X,y,lambd_s) - pivot_primal\n",
    "            print(\"======================\")\n",
    "            print('mu={},nu={}'.format(lambd_s,lambd))\n",
    "            print('norm(wmu-wv) = {}'.format(np.linalg.norm(pivot-ws)))\n",
    "            print('norm(wmu)={},norm(wv)={}'.format(np.linalg.norm(ws),np.linalg.norm(pivot)))\n",
    "            dists[i,j] = abs(dist)\n",
    "            print(\"f_mu - fv= {}\".format(dists[i,j]))\n",
    "        if(verbose):\n",
    "          print(\"step: {}\".format(i))   \n",
    "    mdist = np.mean(dists,axis=1)\n",
    "    vdist = np.var(np.log(dists),axis =1)\n",
    "    print(vdist)\n",
    "    sizes = np.divide(1.0,sizes)\n",
    "    xd = np.log(sizes)\n",
    "    yd = np.log(mdist)\n",
    "    par = np.polyfit(xd, yd, 1, full=True)\n",
    "    slope=par[0][0]\n",
    "    intercept=par[0][1]\n",
    "    xl = [min(xd), max(xd)]\n",
    "    yl = [slope*xx + intercept  for xx in xl]\n",
    "    mang = np.mean(angles,axis = 1)\n",
    "    vang = np.var(angles,axis= 1)\n",
    "    plt.errorbar(np.log(sizes),np.log(mdist),yerr=vdist)\n",
    "    #plt.plot(np.log(sizes),np.log(mdist),marker='o')\n",
    "    label_l = \"y =%.2f x + %.2f\" % (slope,intercept)\n",
    "    print(label_l)\n",
    "    plt.plot(xl,yl,label = label_l)\n",
    "    plt.xlabel(\"Log(m)\")\n",
    "    plt.ylabel(\"Log(|P_m^* - P_n^*|)\")\n",
    "   # plt.title(\"Distance Plot For %s\" % dataname)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 49749; \n",
    "d = 300; \n",
    "filename = \"../datasets/w8a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "#X = preprocessing.normalize(X, norm='l2')\n",
    "lambd = 1.0/n\n",
    "distance_plot(X,y,n,d,lambd,1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 32561; \n",
    "d = 123;\n",
    "filename = \"../datasets/a9a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "#X = preprocessing.normalize(X, norm='l2')\n",
    "lambd = 1.0/n\n",
    "distance_plot(X,y,n,d,lambd,1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 50100; \n",
    "d = 54; \n",
    "filename = \"../datasets/covtype.libsvm.binary.scale\"\n",
    "y, X = readfile(filename,n,d)\n",
    "lambd = 1.0/n\n",
    "distance_plot(X,y,n,d,lambd,1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 32561; \n",
    "d = 123;\n",
    "filename = \"../datasets/a9a\"\n",
    "y, X = readfile(filename,n,d)\n",
    "#X = preprocessing.normalize(X, norm='l2')\n",
    "lambd = 1.0/n\n",
    "U, s, V = np.linalg.svd(X, full_matrices=False)\n",
    "s2 = np.power(s,2)\n",
    "s = s/float(n)\n",
    "s2 = s2/float(n)\n",
    "s2l = s2 + lambd\n",
    "d = np.divide(s,s2l)\n",
    "w = np.dot(np.transpose(V),np.dot(np.diag(d),np.dot(np.transpose(U),y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = np.divide(s,s2l)\n",
    "p = np.dot(np.diag(d),np.dot(np.transpose(U),y))\n",
    "plt.hist(p)\n",
    "plt.savefig('histogram3.eps', facecolor='w', edgecolor='w', orientation='portrait',  format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(d)\n",
    "plt.savefig('histogram2.eps', facecolor='w', edgecolor='w', orientation='portrait',  format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.zeros(123)\n",
    "for i in range(123): \n",
    "    a[i] = np.linalg.norm(np.multiply(V[:,i],np.dot(U[:,i],y)))\n",
    "plt.hist(a)\n",
    "plt.savefig('histogram2.eps', facecolor='w', edgecolor='w', orientation='portrait',  format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tem = np.dot(np.transpose(U),y)\n",
    "plt.scatter(d,tem)\n",
    "plt.savefig('dot_vs_eign.eps', facecolor='w', edgecolor='w', orientation='portrait',  format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d\n",
    "plt.hist(d)\n",
    "plt.savefig('histogram4.eps', facecolor='w', edgecolor='w', orientation='portrait',  format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(s*n)\n",
    "plt.savefig('histogram5.eps', facecolor='w', edgecolor='w', orientation='portrait',  format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inds = s*n < 10 \n",
    "t = np.dot(np.transpose(U[:,inds]),y)\n",
    "plt.hist(t)\n",
    "plt.savefig('histogram_dots_for_small_lambad.eps', facecolor='w', edgecolor='w', orientation='portrait',  format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.transpose(U)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
