{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import math\n",
    "from sklearn import linear_model\n",
    "\n",
    "def primal_func(w,y,X,lambd,verbose=False): # computes the primal value for the given parameter w\n",
    "    n, d = X.shape\n",
    "    pw = 0\n",
    "    for i in range(n): \n",
    "        pw = pw + math.log(1+ math.exp(-1*y[i]*np.dot(w,X[i,:])))\n",
    "    pw = pw/float(n)\n",
    "    pw = pw + 0.5*lambd*np.square(np.linalg.norm(w)) \n",
    "    return pw\n",
    "\n",
    "def readfile(filename, n,d):\n",
    "    y = np.zeros(n) # targets\n",
    "    X = np.zeros((n,d)) # input matrix each row is a sample data point\n",
    "    li = 0 \n",
    "    with open(filename, \"rb\") as f:\n",
    "        for line in f:\n",
    "           if li>=n : \n",
    "             break;\n",
    "           parts = line.split()\n",
    "           y[li] = float(parts[0])\n",
    "           for i in range(len(parts)): \n",
    "                if i >0 and parts[i] != '\\n': \n",
    "                    fparts = parts[i].split(\":\")\n",
    "                    X[li,int(fparts[0])-1] = float(fparts[1])\n",
    "           li = li +1\n",
    "    return (y,X)\n",
    "    \n",
    "def distance_plot(X,y,n,d,lambd,nr,pivotsi,verbose = False):\n",
    "\n",
    "    print(max(np.linalg.norm(X,axis =1 )))\n",
    "    if(verbose):\n",
    "        print(\"Loading Data Accomblished\")\n",
    "    indices = np.random.choice(n, pivotsi, replace=False)\n",
    "    sfilename = \"outputs/optimals_%s\" % dataname\n",
    "    f = open(sfilename,'w');\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    t1,t2 = X.shape\n",
    "    print('t1:{},t2:{}'.format(t1,t2))\n",
    "    for i in range(len(y)): \n",
    "        if y[i] == 2 :\n",
    "            y[i] = -1\n",
    "    n = pivotsi\n",
    "    x0 = np.zeros(d)\n",
    "    f.write(\"{}\\n\".format(d))\n",
    "    \n",
    "    csize = 256\n",
    "    sizes = [csize]\n",
    "    while csize < (n/2):\n",
    "        csize = 2* csize\n",
    "        sizes.append(csize)\n",
    "    clf = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0000000000001, C=1.0/lambd, fit_intercept=False, class_weight=None, random_state=None, solver='lbfgs', max_iter=100000, multi_class='ovr', verbose=1)\n",
    "    pivot = clf.fit(X, y).coef_\n",
    "    print(\"precision:{},pivot_norm:{}\".format(primal_func(pivot,y,X,lambd,verbose=False),np.square(np.linalg.norm(pivot))))\n",
    "    spivot = str(pivot)[2:-2]\n",
    "    spivot = spivot.replace(',',' ')\n",
    "    f.write(\"{}\\n\".format(pivotsi))\n",
    "    for k in range(pivotsi):\n",
    "      f.write(\"{} \".format(indices[k]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(spivot)\n",
    "    f.write(\"\\n\")\n",
    "    dists= np.zeros((len(sizes),nr))\n",
    "    angles = np.zeros((len(sizes),nr))\n",
    "    for i in range(len(sizes)):\n",
    "        subsamplsi = sizes[i]\n",
    "        f.write(\"{} {}\\n\".format(subsamplsi,nr))\n",
    "        for j in range(nr):\n",
    "            f.write(\"{}\\n\".format(j))\n",
    "            print('subsample size:{}'.format(subsamplsi))\n",
    "            subindices = np.random.choice(n, subsamplsi, replace=True)\n",
    "            for k in range(subsamplsi):\n",
    "                f.write(\"{} \".format(indices[subindices[k]]))\n",
    "            f.write(\"\\n\")\n",
    "            subX = X[subindices,:]\n",
    "            suby = y[subindices]\n",
    "            print(len(suby))\n",
    "            clf = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0000000001, C=1.0/lambd, fit_intercept=True, class_weight=None, random_state=None, solver='lbfgs', max_iter=1000000, multi_class='ovr', verbose=1)\n",
    "            clf.fit(subX, suby)\n",
    "            ws = clf.coef_\n",
    "            sws = str(ws)[2:-2]\n",
    "            sws = sws.replace(',',' ')\n",
    "            f.write(sws)\n",
    "            f.write(\"\\n\")\n",
    "            dist = pivot - ws\n",
    "            dists[i,j] = np.square(np.linalg.norm(dist))\n",
    "            x0xm = x0-ws\n",
    "            angles[i,j] = np.arccos(np.dot(dist,np.transpose(x0xm))/(np.linalg.norm(x0xm)*np.linalg.norm(dist)))\n",
    "        if(verbose):\n",
    "          print(\"step: {}\".format(i))   \n",
    "    f.close()\n",
    "    mdist = np.mean(dists,axis=1)\n",
    "    vdist = np.var(dists,axis =1)\n",
    "    xd = np.log(sizes)\n",
    "    yd = np.log(mdist)\n",
    "    par = np.polyfit(xd, yd, 1, full=True)\n",
    "    slope=par[0][0]\n",
    "    intercept=par[0][1]\n",
    "    xl = [min(xd), max(xd)]\n",
    "    yl = [slope*xx + intercept  for xx in xl]\n",
    "    mang = np.mean(angles,axis = 1)\n",
    "    vang = np.var(angles,axis= 1)\n",
    "    #plt.errorbar(np.log(sizes),np.log(mdist),yerr=np.log(vdist))\n",
    "    plt.plot(np.log(sizes),np.log(mdist),marker='o')\n",
    "    label_l = \"y =%.2f x + %.2f\" % (slope,intercept)\n",
    "    print(label_l)\n",
    "    plt.plot(xl,yl,label = label_l)\n",
    "    plt.xlabel(\"Log(m)\")\n",
    "    plt.ylabel(\"Log(|w_m^* - w_n^*|^2)\")\n",
    "   # plt.title(\"Distance Plot For %s\" % dataname)\n",
    "    filename = 'outputs/distance_%s.eps' % dataname\n",
    "    plt.legend()\n",
    "    plt.savefig(filename, format='eps')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11babecd0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1124e2510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataname = \"a9a\"\n",
    "n = 32561;\n",
    "d = 123; \n",
    "lambd = 1.0/(n*math.sqrt(n))\n",
    "nr = 150 \n",
    "floc = \"datasets/%s\" % dataname; \n",
    "X, y = ReadData(n,d,floc)\n",
    "clf = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0000000001, C=1.0/lambd,warm_start = True, fit_intercept=True, class_weight=None, random_state=None, solver='lbfgs', max_iter=1, multi_class='ovr', verbose=1)\n",
    "clfo = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0000000001, C=1.0/lambd,warm_start = False, fit_intercept=True, class_weight=None, random_state=None, solver='lbfgs', max_iter=1000000, multi_class='ovr', verbose=1)\n",
    "clfo.fit(X, y)\n",
    "ws = clfo.coef_\n",
    "dists = np.zeros((nr,1))\n",
    "for i in range(nr): \n",
    "    clf.fit(X,y)\n",
    "    dists[i] = np.linalg.norm(np.subtract(clf.coef_,ws))\n",
    "plt.plot(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.45977206],\n",
       "       [ 12.22838581],\n",
       "       [ 11.93834182],\n",
       "       [ 11.73975321],\n",
       "       [ 11.67580837],\n",
       "       [ 11.60516581],\n",
       "       [ 11.56344075],\n",
       "       [ 11.53214044],\n",
       "       [ 11.50951339],\n",
       "       [ 11.49081949],\n",
       "       [ 11.47863443],\n",
       "       [ 11.45736106],\n",
       "       [ 11.44591498],\n",
       "       [ 11.43202819],\n",
       "       [ 11.42281263],\n",
       "       [ 11.40967154],\n",
       "       [ 11.40100397],\n",
       "       [ 11.38305373],\n",
       "       [ 11.37220573],\n",
       "       [ 11.35686828],\n",
       "       [ 11.34881529],\n",
       "       [ 11.33629215],\n",
       "       [ 11.32773329],\n",
       "       [ 11.23825205],\n",
       "       [ 11.2313779 ],\n",
       "       [ 11.19727692],\n",
       "       [ 11.19083988],\n",
       "       [ 11.05099196],\n",
       "       [ 11.04535463],\n",
       "       [ 10.71270285],\n",
       "       [ 10.70910518],\n",
       "       [ 10.65462995],\n",
       "       [ 10.65092378],\n",
       "       [ 10.63916276],\n",
       "       [ 10.6346142 ],\n",
       "       [ 10.56453409],\n",
       "       [ 10.56094706],\n",
       "       [ 10.53769698],\n",
       "       [ 10.53212753],\n",
       "       [ 10.52383287],\n",
       "       [ 10.38244638],\n",
       "       [ 10.38015726],\n",
       "       [ 10.35303856],\n",
       "       [ 10.35061772],\n",
       "       [ 10.33800531],\n",
       "       [ 10.33464853],\n",
       "       [ 10.28003515],\n",
       "       [ 10.27041021],\n",
       "       [ 10.24305903],\n",
       "       [ 10.23710058],\n",
       "       [ 10.21519464],\n",
       "       [ 10.21022872],\n",
       "       [ 10.16741673],\n",
       "       [ 10.163594  ],\n",
       "       [ 10.15865671],\n",
       "       [ 10.15551267],\n",
       "       [ 10.14857041],\n",
       "       [ 10.14489729],\n",
       "       [ 10.12730743],\n",
       "       [ 10.1095497 ],\n",
       "       [ 10.10600251],\n",
       "       [ 10.10038737],\n",
       "       [ 10.09710178],\n",
       "       [ 10.0917288 ],\n",
       "       [ 10.08871689],\n",
       "       [ 10.07382328],\n",
       "       [ 10.06938016],\n",
       "       [ 10.06208965],\n",
       "       [ 10.05706503],\n",
       "       [ 10.04523898],\n",
       "       [ 10.03737542],\n",
       "       [ 10.01990762],\n",
       "       [ 10.01720174],\n",
       "       [ 10.00080756],\n",
       "       [  9.9863853 ],\n",
       "       [  9.98269804],\n",
       "       [  9.97752747],\n",
       "       [  9.9572645 ],\n",
       "       [  9.9509473 ],\n",
       "       [  9.9479516 ],\n",
       "       [  9.94372391],\n",
       "       [  9.94140335],\n",
       "       [  9.93721554],\n",
       "       [  9.93489123],\n",
       "       [  9.93074251],\n",
       "       [  9.9284138 ],\n",
       "       [  9.92430348],\n",
       "       [  9.92196964],\n",
       "       [  9.91789704],\n",
       "       [  9.91555725],\n",
       "       [  9.91152165],\n",
       "       [  9.90917501],\n",
       "       [  9.90517569],\n",
       "       [  9.90282124],\n",
       "       [  9.89885741],\n",
       "       [  9.89649409],\n",
       "       [  9.89256493],\n",
       "       [  9.89019161],\n",
       "       [  9.74365341],\n",
       "       [  9.74121709]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 49990;\n",
    "d = 22; \n",
    "dataname = \"ijcnn1\"\n",
    "lambd = 1.0/(n*math.sqrt(n))\n",
    "nr = 10 \n",
    "distance_plot(dataname,n,d,lambd,nr,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataname = \"w8a\"\n",
    "n = 49749;\n",
    "d = 300; \n",
    "lambd = 1.0/(math.sqrt(n))\n",
    "nr = 1 \n",
    "distance_plot(dataname,n,d,lambd,1,n,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dataname = \"rcv1_train.binary\"\n",
    "n = 20242;\n",
    "d = 47236; \n",
    "lambd = 1.0/(n*math.sqrt(n))\n",
    "nr = 5 \n",
    "distance_plot(dataname,n,d,lambd,1,n,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataname = \"a9a\"\n",
    "n = 32561;\n",
    "d = 123; \n",
    "lambd = 1.0/(n*math.sqrt(n))\n",
    "nr = 10 \n",
    "distance_plot(dataname,n,d,lambd,1,n,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataname = \"covtype.libsvm.binary.scale\"\n",
    "n = 581012;\n",
    "d = 54; \n",
    "lambd = 1.0/(n*math.sqrt(n))\n",
    "nr = 3 \n",
    "distance_plot(dataname,n,d,lambd,1,n,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ls_loss(X,y,b): \n",
    "    n, d = X.shape\n",
    "    return np.square(np.linalg.norm(X.dot(np.transpose(b))-y))/n\n",
    "def distance_plot_ls(X,y,b,n,d,nr,pivotsi,dataname,verbose = False):\n",
    "    print(max(np.linalg.norm(X,axis =1 )))\n",
    "    if(verbose):\n",
    "        print(\"Loading Data Accomblished\")\n",
    "    indices = np.random.choice(n, pivotsi, replace=False)\n",
    "    sfilename = \"outputs/optimals_%s\" % dataname\n",
    "    f = open(sfilename,'w');\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    n = pivotsi\n",
    "    x0 = np.zeros(d)\n",
    "    f.write(\"{}\\n\".format(d))\n",
    "    sizes = [64,128,256,512,1024,2048,4096,8192,16000,32000,64000]\n",
    "    clf = linear_model.LinearRegression()\n",
    "    res = clf.fit(X,y)\n",
    "    pivot = res.coef_ \n",
    "    spivot = str(pivot)[2:-2]\n",
    "    spivot = spivot.replace(',',' ')\n",
    "    f.write(\"{}\\n\".format(pivotsi))\n",
    "    for k in range(pivotsi):\n",
    "      f.write(\"{} \".format(indices[k]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(spivot)\n",
    "    f.write(\"\\n\")\n",
    "    dists= np.zeros((len(sizes),nr))\n",
    "    angles = np.zeros((len(sizes),nr))\n",
    "    for i in range(len(sizes)):\n",
    "        subsamplsi = sizes[i]\n",
    "        f.write(\"{} {}\\n\".format(subsamplsi,nr))\n",
    "        for j in range(nr):\n",
    "            f.write(\"{}\\n\".format(j))\n",
    "            subindices = np.random.choice(n, subsamplsi, replace=True)\n",
    "            for k in range(subsamplsi):\n",
    "                f.write(\"{} \".format(indices[subindices[k]]))\n",
    "            f.write(\"\\n\")\n",
    "            subX = X[subindices,:]\n",
    "            suby = y[subindices]\n",
    "            print(len(suby))\n",
    "            clf = linear_model.LinearRegression()\n",
    "            res = clf.fit(subX,suby)\n",
    "            ws = res.coef_\n",
    "            sws = str(ws)[2:-2]\n",
    "            sws = sws.replace(',',' ')\n",
    "            f.write(sws)\n",
    "            f.write(\"\\n\")\n",
    "            dist = ls_loss(X,y,ws)-ls_loss(X,y,b)\n",
    "            dists[i,j] = np.log10(dist)\n",
    "            x0xm = x0-ws\n",
    "           # angles[i,j] = np.arccos(np.dot(dist,np.transpose(x0xm))/(np.linalg.norm(x0xm)*np.linalg.norm(dist)))\n",
    "        if(verbose):\n",
    "          print(\"step: {}\".format(i))   \n",
    "    f.close()\n",
    "    mdist = np.mean(dists,axis=1)\n",
    "    vdist = np.var(dists,axis =1)\n",
    "    mang = np.mean(angles,axis = 1)\n",
    "    vang = np.var(angles,axis= 1)\n",
    "    plt.errorbar(np.log10(sizes),mdist,yerr=vdist)\n",
    "    plt.xlabel(\"Log(m)\")\n",
    "    plt.ylabel(\"Log(|x_m^* - x_n^*|^2)\")\n",
    "    plt.title(\"Distance Plot For %s\" % dataname)\n",
    "    filename = 'outputs/distance_%s.pdf' % dataname\n",
    "    plt.savefig(filename, format='pdf')\n",
    "    plt.close()\n",
    "    plt.errorbar(sizes,mang,yerr=vang)\n",
    "    plt.xlabel(\"m\")\n",
    "    plt.ylabel(\"Angle(x_n^* - x_m^*, -x_m^*)\")\n",
    "    plt.title(\"Angle Plot For %s\" % dataname)\n",
    "    filename = 'outputs/angle_%s.pdf' % dataname\n",
    "    plt.savefig(filename, format='pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 50 \n",
    "n = 64000\n",
    "nr = 3 \n",
    "pivotsi=n \n",
    "X = np.random.normal(loc=0.0, scale=1.0, size=(n,d))\n",
    "b = np.random.uniform(low = 0.0, high =1.0,size= (d,1))\n",
    "y = np.dot(X,b) + np.random.normal(loc=0.0,scale=1.0,size=(n,1))\n",
    "distance_plot_ls(X,y,np.transpose(b),n,d,nr,pivotsi,\"syntatic_4\",verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.random.uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pow(2,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 49990;\n",
    "d = 22; \n",
    "dataname = \"ijcnn1\"\n",
    "floc = \"datasets/%s\" % dataname; \n",
    "def mis_class(w,X,y): \n",
    "    n,d = X.shape\n",
    "    pw = 0\n",
    "    for i in range(n): \n",
    "       if (y[i]*np.dot(w,X[i,:])<0):\n",
    "        pw = pw + 1\n",
    "    pw = pw/(1.0*n)\n",
    "    return pw\n",
    "#############################\n",
    "X, y = ReadData(n,d,floc)\n",
    "sub = np.random.choice(n, n, replace=False)\n",
    "X = X[sub,:]\n",
    "y = y[sub]\n",
    "Xt = X[40000:,:]\n",
    "yt = y[40000:]\n",
    "X = X[1:40000,:]\n",
    "y = y[1:40000]\n",
    "n,d = X.shape; \n",
    "ls = 10; \n",
    "lams = [0]*ls; \n",
    "sizes = [64,128,256,512,1024,2048,4096,8192,16000,32000]\n",
    "for i in range(ls):\n",
    "    lams[i]= pow(4,-1*(i+1))\n",
    "opt_lams = [0]*len(sizes) \n",
    "for i in range(len(sizes)):\n",
    "    subsamplsi = sizes[i]\n",
    "    print(subsamplsi)\n",
    "    subindices = np.random.choice(n, subsamplsi, replace=False)\n",
    "    subX = X[subindices,:]\n",
    "    suby = y[subindices]\n",
    "    err = float(\"inf\"); \n",
    "    for j in range(ls):\n",
    "     clf = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0000000001, C=1.0/lams[j], fit_intercept=False, class_weight=None, random_state=None, solver='lbfgs', max_iter=1000000, multi_class='ovr', verbose=1)\n",
    "     clf.fit(subX, suby)\n",
    "     ws = clf.coef_\n",
    "     err_n = mis_class(ws,subX,suby)\n",
    "     print(err_n)\n",
    "     if err_n<err: \n",
    "        err = err_n\n",
    "        opt_lams[i] = lams[j]\n",
    "     \n",
    "####################################\n",
    "#distance_plot(dataname,n,d,lambd,nr,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_lams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.log(opt_lams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yt>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(yt>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(yt<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(y>0)/(1.0*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(y<0)/(1.0*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "string = \"%.2f\" % math.sqrt(2)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9deae6c88df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "eigs = np.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
